<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>MQTT EV3 </title>
    <script src="http://code.jquery.com/jquery-3.3.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.1/dist/speech-commands.min.js"></script>

    <script type="text/javascript" src="/socket.io/socket.io.js"></script>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link type="text/css" rel="stylesheet" href="stylesheets/materialize.min.css" media="screen,projection" />
    <link rel="stylesheet" href="./stylesheets/button.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    
    <script type="text/javascript">
        var socket = null;
        var timer = null;
        var state = 0;
        $(document).ready(function () {

            data={}

            socket = io.connect(); // 3000port
            // Node.js보낸 데이터를 수신하는 부분
            socket.on("socket_evt_mqtt", function (data) {
                state = JSON.parse(data);
                if (state == 1)
                    $("#state-container").html("<br><img src=\'\/images\/ing.png\' width=\'200\' height=\'150\'>");
                else if (state == 2)
                    $("#state-container").html("<br><img src=\'\/images\/conn.png\' width=\'200\' height=\'150\'>");
                else
                    $("#state-container").html("<br><img src=\'\/images\/discon.png\' width=\'200\' height=\'150\'>");
            });
            if (timer == null) {
                timer = window.setInterval("timer1()", 500);
            }
        });

        function timer1() {
            socket.emit("socket_evt_mqtt", JSON.stringify({}));
            send2ev3(data);
        }

        function ev3stop()
        {
            socket.emit("socket_evt_brick", JSON.stringify({ state: new String('stop') }));
        }

        function send2ev3(value) {

            if (state == 2) 
            {              
                socket.emit("socket_evt_brick", JSON.stringify(value)); 

            }
        }


        function setEV3IP() {
            var value = document.getElementById("ev3ip").value;
            if(value != null && value.length > 1)
                socket.emit("socket_evt_ip", JSON.stringify({ ev3ip: new String(value) }));
        }
    </script>
</head>

<body style='background-color: #e0f2f1 ;'>
    <!--JavaScript at end of body for optimized loading-->
    <div class="card-panel teal white-text lighten-2">
        <h5>인공 지능 판별기: 음성</h5>
    </div>

    <div class="container" >
        <div class="row">
            <div class="col s12">
                <div class="row">
                    <div class="input-field col s3">
                        <input type="text" id="ev3ip" value="ev3dev">
                        <label for="ev3ip">EV3 IP 주소</label>
                    </div>
                    <div class="input-field col s4">
                        <button class="waves-effect waves-light btn" onclick="init()"><i
                                class="material-icons left">play_circle_filled</i>시작</button>
                        <button class="waves-effect waves-light btn" onclick="wstop()"><i
                                class="material-icons left">cancel</i>중지</button>
                    </div>
                    <div class="input-field col s5">
                        <button class="waves-effect waves-light btn" onclick="window.location.href='./MQTT.html'"><i
                            class="material-icons left">preview</i>이미지</button>
                        <button class="waves-effect waves-light btn" onclick="window.location.href='./pose.html'"><i
                                class="material-icons left">accessibility</i>포즈</button>
                        <button class="waves-effect waves-light btn" onclick="window.location.href='./audio.html'" ><i
                                    class="material-icons left">mic</i>음성</button>    
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col s4">
                <div class="card">
                    <div class="card-content" style="font-size:20px">
                        <b>EV3 상태</b>
                    </div>
                    <div class="divider"></div>
                    <div class="card-image" id="state-container" style="height:200px">
                    </div>
                </div>
            </div>
            <div class="col s4">
                <div class="card">
                    <div class="card-content" style="font-size:20px">
                        <b>마이크</b>
                    </div>
                    <div class="divider"></div>
                    <div class="card-image" id="mic-container" style="height:200px;padding-left:10px">
                    </div>
                </div>
            </div>
            <div class="col s4">
                <div class="card">
                    <div class="card-content" style="font-size:20px">
                        <b>판 정</b>
                    </div>
                    <div class="divider"></div>
                    <div class="card-image" style="height:200px;padding-left:10px" >
                        <br>
                        <div id="label-container"></div>
                        <div id="brick"></div>
                    </div>
                </div>
            </div>
        </div>

    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>
    <script type="text/javascript">
      // more documentation available at
    // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/kgmLimmw_/";
   
    async function createModel() {
       const checkpointURL = URL + "model.json"; // model topology
       const metadataURL = URL + "metadata.json"; // model metadata

       const recognizer = speechCommands.create(
           "BROWSER_FFT", // fourier transform type, not useful to change
           undefined, // speech commands vocabulary feature, not useful for your models
           checkpointURL,
           metadataURL);

       // check that model and metadata are loaded via HTTPS requests.
       await recognizer.ensureModelLoaded();

       return recognizer;
   }
   var colors = [
		'#1E90FF',
		'#F7464A',
		'#acc236',
		'#166a8f',
		'#00a950',
		'#58595b',
		'#8549ba'
    ];
    
    let recognizer;
   
    async function init() {
       const recognizer = await createModel();
       const classLabels = recognizer.wordLabels(); // get class labels
       const labelContainer = document.getElementById("label-container");
       for (let i = 0; i < classLabels.length; i++) {
           labelContainer.appendChild(document.createElement("div"));
       }

       wstop();
       setEV3IP();
       
       $("#mic-container").html("<br><img src=\'\/images\/mic.png\' width=\'200\' height=\'150\'>");


       // listen() takes two arguments:
       // 1. A callback function that is invoked anytime a word is recognized.
       // 2. A configuration object with adjustable fields
       recognizer.listen(result => {
           const scores = result.scores; // probability of prediction for each class
           // render the probability scores per class
    
           for (let i = 0; i < classLabels.length; i++) {
                const classPrediction = classLabels[i] + ": " + parseInt(result.scores[i].toFixed(2) *100)
                +"%";
                data[classLabels[i]] = parseInt(result.scores[i].toFixed(2) *100);
                labelContainer.childNodes[i].innerHTML ="<div style='font-size:18px;color:"+colors[i]
                +";font-weight:bold'>"+classPrediction
                +"</font>";
            }

       }, {
           includeSpectrogram: true, // in case listen should return result.spectrogram
           probabilityThreshold: 0.75,
           invokeCallbackOnNoiseAndUnknown: true,
           overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
       });

       // Stop the recognition in 5 seconds.
       // setTimeout(() => recognizer.stopListening(), 5000);
    }

    async function wstop() {
            ev3stop();
            if(recognizer)
                await recognizer.stopListening();
            //document.getElementById("webcam-container").removeChild(webcam.canvas);
       
    }

     
    </script>


</body>

</html>